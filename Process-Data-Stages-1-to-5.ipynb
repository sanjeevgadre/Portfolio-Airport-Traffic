{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_excel_data(file_name):\n",
    "    '''\n",
    "    \n",
    "    Read existing raw data file in the excel format, standardize the column names and alter column position\n",
    "    for better human readability\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    dat = pd.read_excel(file_name, na_filter = False, convert_float = False)\n",
    "\n",
    "    # Setting the column names\n",
    "    dat.columns = ['num', 'flight', 'operator', 'aircraft', 'frequency', 'from', 'to_time', 'to', \n",
    "                   'from_time', 'eff_from', 'eff_to']  \n",
    "\n",
    "    # Altering the column positions\n",
    "    dat.insert(1, 'operator', dat.pop('operator'))\n",
    "    dat.insert(6, 'from_time', dat.pop('from_time'))\n",
    "    dat.insert(7, 'to', dat.pop('to'))\n",
    "    \n",
    "    return dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wrangle_rows(df):\n",
    "    '''\n",
    "    \n",
    "    Drop repeated instances of header rows\n",
    "    Drop the city name headers by first moving the city name to the <num> field and renaming the <num> field\n",
    "    as <station>\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    # dropping superflous header rows\n",
    "    trash_idx = [i for i in range(df.shape[0]) if ((not isinstance(df.iloc[i, 0], float)) and \n",
    "                                                    (df.iloc[i, 4] == 'Frequency'))]\n",
    "      \n",
    "    df = df.drop(trash_idx, axis = 0)\n",
    "    df = df.reset_index() # resetting the index after dropping rows\n",
    "    df = df.drop('index', axis = 1) # dropping the previous index\n",
    "    \n",
    "    # dropping city names subheader rows\n",
    "    trash_idx = [i for i in range(df.shape[0]) if isinstance(df.iloc[i, 0], str)]\n",
    "    \n",
    "    for i in range(len(trash_idx)-1):\n",
    "        df.iloc[trash_idx[i] + 1: trash_idx[i+1], 0] = df.iloc[trash_idx[i], 0]\n",
    "    \n",
    "    # Separately for the last sub-head in the list\n",
    "    df.iloc[trash_idx[-1] + 1: df.shape[0], 0] = df.iloc[trash_idx[-1], 0]\n",
    "        \n",
    "    df = df.drop(trash_idx, axis = 0) \n",
    "    df = df.reset_index() # resetting the index after dropping rows\n",
    "    df = df.drop('index', axis = 1) # dropping the previous index\n",
    "    \n",
    "    df = df.rename(columns = {'num': 'station'}, errors = 'raise')\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wrangle_cols(df):\n",
    "    '''\n",
    "    Copying the station name to either the <from> or <to> column appropriately and dropping the <station> column.\n",
    "    \n",
    "    '''\n",
    "    idx = df.loc[:,'from'] == ''\n",
    "    df.loc[idx, 'from'] = df.loc[idx, 'station']\n",
    "\n",
    "    idx = df.loc[:, 'to'] == ''\n",
    "    df.loc[idx, 'to'] = df.loc[idx, 'station']\n",
    "\n",
    "    df = df.drop(['station'], axis = 1)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_city_spelling(df, city_names):\n",
    "    '''\n",
    "    Fixing known city spelling errors\n",
    "    '''\n",
    "    \n",
    "    for i in range(df.shape[0]):\n",
    "            if df['from'][i] in list(city_names.keys()): df['from'][i] = city_names[df['from'][i]]\n",
    "            if df['to'][i] in list(city_names.keys()): df['to'][i] = city_names[df['to'][i]]\n",
    "            \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wrangle_iata_codes(df, city_to_codes):\n",
    "    '''\n",
    "    Convert the city names in the <from> and <to> columns to its equivalent IATA code. \n",
    "    Capture in a separate list, the cities for whom the IATA code is missing.\n",
    "    '''\n",
    "    \n",
    "    # List to capture city names in the df for which an equivalent IATA code is missing\n",
    "    missing_city_names = []\n",
    "      \n",
    "    idx = [i for i in range(df.shape[0]) if not df['from'][i].isupper()]\n",
    "    for i in idx: \n",
    "        try: \n",
    "            df['from'][i] = city_to_codes[df['from'][i]]\n",
    "        except KeyError:\n",
    "            if df['from'][i] not in missing_city_names:\n",
    "                missing_city_names.append(df['from'][i])\n",
    "        \n",
    "    idx = [i for i in range(df.shape[0]) if not df['to'][i].isupper()]\n",
    "    for i in idx: \n",
    "        try:\n",
    "            df['to'][i] = city_to_codes[df['to'][i]]\n",
    "        except KeyError:\n",
    "            if df['to'][i] not in missing_city_names:\n",
    "                missing_city_names.append(df['to'][i])\n",
    "                \n",
    "    # Flag to track if there are missing city names\n",
    "    if len(missing_city_names) !=0: flag = 'down'\n",
    "    else: flag = 'up'\n",
    "\n",
    "        \n",
    "    return flag, missing_city_names, df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing for Vistara\n",
      "(Stage I) Read raw data: has 554 records\n",
      "(Stage II) Deleted header rows: now has 515 records\n",
      "(Stage III) Updated the <From>(or <To>) column with Station name\n",
      "(Stage IV) Fixed known city name spelling errors\n",
      "(Stage V) Replaced city names with corresponding IATA codes and saved the processed file\n",
      "\n",
      "Processing for SpiceJet\n",
      "(Stage I) Read raw data: has 1680 records\n",
      "(Stage II) Deleted header rows: now has 1592 records\n",
      "(Stage III) Updated the <From>(or <To>) column with Station name\n",
      "(Stage IV) Fixed known city name spelling errors\n",
      "(Stage V) Replaced city names with corresponding IATA codes and saved the processed file\n",
      "\n",
      "Processing for TruJet\n",
      "(Stage I) Read raw data: has 201 records\n",
      "(Stage II) Deleted header rows: now has 174 records\n",
      "(Stage III) Updated the <From>(or <To>) column with Station name\n",
      "(Stage IV) Fixed known city name spelling errors\n",
      "(Stage V) Replaced city names with corresponding IATA codes and saved the processed file\n",
      "\n",
      "Processing for Air_India\n",
      "(Stage I) Read raw data: has 1204 records\n",
      "(Stage II) Deleted header rows: now has 1125 records\n",
      "(Stage III) Updated the <From>(or <To>) column with Station name\n",
      "(Stage IV) Fixed known city name spelling errors\n",
      "(Stage V) Replaced city names with corresponding IATA codes and saved the processed file\n",
      "\n",
      "Processing for Star_Air\n",
      "(Stage I) Read raw data: has 83 records\n",
      "(Stage II) Deleted header rows: now has 74 records\n",
      "(Stage III) Updated the <From>(or <To>) column with Station name\n",
      "(Stage IV) Fixed known city name spelling errors\n",
      "(Stage V) Replaced city names with corresponding IATA codes and saved the processed file\n",
      "\n",
      "Processing for Indigo\n",
      "(Stage I) Read raw data: has 4501 records\n",
      "(Stage II) Deleted header rows: now has 4354 records\n",
      "(Stage III) Updated the <From>(or <To>) column with Station name\n",
      "(Stage IV) Fixed known city name spelling errors\n",
      "(Stage V) Replaced city names with corresponding IATA codes and saved the processed file\n",
      "\n",
      "Processing for Air_Asia\n",
      "(Stage I) Read raw data: has 641 records\n",
      "(Stage II) Deleted header rows: now has 608 records\n",
      "(Stage III) Updated the <From>(or <To>) column with Station name\n",
      "(Stage IV) Fixed known city name spelling errors\n",
      "(Stage V) Replaced city names with corresponding IATA codes and saved the processed file\n",
      "\n",
      "Processing for Go_Air\n",
      "(Stage I) Read raw data: has 1051 records\n",
      "(Stage II) Deleted header rows: now has 1003 records\n",
      "(Stage III) Updated the <From>(or <To>) column with Station name\n",
      "(Stage IV) Fixed known city name spelling errors\n",
      "(Stage V) Replaced city names with corresponding IATA codes and saved the processed file\n",
      "\n",
      "Processing for Alliance_Air\n",
      "(Stage I) Read raw data: has 498 records\n",
      "(Stage II) Deleted header rows: now has 431 records\n",
      "(Stage III) Updated the <From>(or <To>) column with Station name\n",
      "(Stage IV) Fixed known city name spelling errors\n",
      "(Stage V) Replaced city names with corresponding IATA codes and saved the processed file\n"
     ]
    }
   ],
   "source": [
    "raw_data_dir_path ='./data/raw/excel'\n",
    "stage_1_data_dir_path = './data/processed/stage-1'\n",
    "\n",
    "# Getting list of files in the directory\n",
    "_, _, raw_file_names = next(os.walk(raw_data_dir_path))\n",
    "_, _, stage_1_file_names = next(os.walk(stage_1_data_dir_path))\n",
    "\n",
    "# Retaining only Excel files from raw and stage-1 data\n",
    "raw_file_names = [i for i in raw_file_names if '.xlsx' in i]\n",
    "stage_1_file_names = [i for i in stage_1_file_names if '.xlsx' in i]\n",
    "\n",
    "# Loading the required dictionaries\n",
    "##### Correcting know city name spelling errors\n",
    "with open('./data/processed/dicts/city_spelling_corrected_dict.txt', 'rb') as handle:\n",
    "    city_names = pickle.loads(handle.read())\n",
    "##### Mapping city names to corresponding IATA codes\n",
    "with open('./data/processed/dicts/city_to_codes_dict.txt', 'rb') as handle:\n",
    "    city_to_codes = pickle.loads(handle.read()) \n",
    "\n",
    "file_names = [value for value in raw_file_names if value not in stage_1_file_names]\n",
    "\n",
    "# Processing individual files\n",
    "for file_name in file_names:\n",
    "    print('\\nProcessing for %s' % file_name.split('.')[0])\n",
    "    \n",
    "    readpath = raw_data_dir_path + '/' + file_name\n",
    "    dat = read_excel_data(readpath)\n",
    "    print('(Stage I) Read raw data: has %i records' % dat.shape[0])\n",
    "    \n",
    "    dat = wrangle_rows(dat)\n",
    "    print('(Stage II) Deleted header rows: now has %i records' % dat.shape[0])\n",
    "    \n",
    "    dat = wrangle_cols(dat)\n",
    "    print('(Stage III) Updated the <From>(or <To>) column with Station name')\n",
    "    \n",
    "    dat = fix_city_spelling(dat, city_names)\n",
    "    print('(Stage IV) Fixed known city name spelling errors')\n",
    "    \n",
    "    flag, missing_city_names, dat = wrangle_iata_codes(dat, city_to_codes)\n",
    "    if flag == 'up':\n",
    "        savepath = './data/processed/stage-1/' + file_name\n",
    "        dat.to_excel(savepath)\n",
    "        print('(Stage V) Replaced city names with corresponding IATA codes and saved the processed file')\n",
    "    else:\n",
    "        print('(Stage V)There are missing IATA codes and/or incorrectly spelt city names.')\n",
    "        print('File partially processed and not saved.')\n",
    "        print('The list of city names either with wrong spelling or missing IATA codes\\n', missing_city_names)\n",
    "        print('Fix errors in the data dictionaries and process again.')\n",
    "        print(' Process will begin from the file that had missing IATA codes')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
