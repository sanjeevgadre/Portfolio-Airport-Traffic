{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creates three dictionaries and saves them as binary files:\n",
    "<ul>\n",
    "    <li>Maps incorrect city name spellings to correct/standard spellings\n",
    "    <li>Maps city names to corresponding IATA codes.\n",
    "    <li>Maps IATA codes to corresponding city names.\n",
    "    <li>Maps carrier codes to corresponding passenger load factors.\n",
    "    <li>Maps carrier+aircraft_type combination to carrying capacity.\n",
    "</ul>\n",
    "<b>These dictionaries must be rebuilt everytime a new city code is to be added or city name spelling is to be corrected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "This dictionary must be updated/extended everytime an incorrect spelling for a city, already in the \n",
    "city_to_code and code_to_city dictionaries, is encountered in the raw data.\n",
    "\n",
    "The entry in the dictionary is in the form {'incorrect_spelling' : 'correct_spelling'}.\n",
    "\n",
    "'''\n",
    "\n",
    "city_names = {'Delhi' : 'New Delhi', 'Bhubaneshwar' : 'Bhubaneswar', 'Trivandrum' : 'Thiruvananthapuram', \n",
    "              'Pondicherry' : 'Puducherry', 'Porbander' : 'Porbandar', 'Tirupathi' : 'Tirupati', \n",
    "              'Tuticorin' : 'Thoothukudi', 'Vizag' : 'Visakhapatnam', 'Cuddapah': 'Kadapa', \n",
    "              'Jalgoan' : 'Jalgaon', 'Rajamundry' : 'Rajahmundry', 'Aizawal' : 'Aizawl', \n",
    "              'Trichy' : 'Tiruchirappally', 'Bathinda' : 'Bhatinda', 'Passighat' : 'Pasighat'}\n",
    "\n",
    "with open('./data/processed/city_spelling_corrected_dict.txt', 'w+b') as handle:\n",
    "    pickle.dump(city_names, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "These dictionaries must be updated/extended everytime a new city and its corresponding IATA code needs to be \n",
    "added to the airports-code.csv file. This need for addition will be identified when processing raw data.\n",
    "\n",
    "The entry in the dictioaries are in the form {'city' : 'IATA_code'} and {'IATA-code' : 'city'} respectively\n",
    "\n",
    "'''\n",
    "\n",
    "city_codes = pd.read_csv('./data/raw/airports-code.csv')\n",
    "\n",
    "city_to_codes = dict(zip(city_codes.city, city_codes.iata_code))\n",
    "with open('./data/processed/city_to_codes_dict.txt', 'w+b') as handle:\n",
    "    pickle.dump(city_to_codes, handle)\n",
    "    \n",
    "codes_to_city = dict(zip(city_codes.iata_code, city_codes.city))\n",
    "with open('./data/processed/codes_to_city_dict.txt', 'w+b') as handle:\n",
    "    pickle.dump(codes_to_city, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "This dictionary must be updated/extended when the passenger load factors of individual carriers change or a \n",
    "new carrier is added. The need to include a carrier will be identified when a new carrier is \n",
    "encountered when processing raw data.\n",
    "\n",
    "The load factor data is available on the DGCA website https://dgca.gov.in/digigov-portal/ and is updated\n",
    "monthly. The current data is for Jan 2020. DGCA does not separately report data for Alliance Air so assumed \n",
    "the same load factor as its parent i.e. Air India.\n",
    "\n",
    "The entry in the dictionary is in the form {'carrier' : 'passenger_load_factor_in_decimels'}\n",
    "\n",
    "'''\n",
    "\n",
    "carrier_plf = {'IND' : 0.878, 'GOW' : 0.887, 'AAS' : 0.780, 'AI' : 0.780, 'I5' : 0.793, 'TRJ' : 0.798, \n",
    "               'OG' : 0.797, 'UK' : 0.811, 'SG' : 0.915}\n",
    "\n",
    "with open('./data/processed/carrier_plf_dict.txt', 'w+b') as handle:\n",
    "    pickle.dump(carrier_plf, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "This dictionary must be updated/extended everytime a new carrier starts service or a new aircraft type is \n",
    "added by an existing carrier to their fleet. This need for addition will be identified when processing \n",
    "raw data.\n",
    "\n",
    "The entry in the dictionary is in the form {'aircraft_type' : 'capacity'}\n",
    "\n",
    "'''\n",
    "\n",
    "craft_capacity = pd.read_csv('./data/raw/aircraft_capacity.csv')\n",
    "craft_capacity = dict(zip(craft_capacity.operator + '-' + craft_capacity.aircraft, craft_capacity.capacity))\n",
    "with open('./data/processed/carrier_aircraft_combo_capacity_dict.txt', 'w+b') as handle:\n",
    "    pickle.dump(craft_capacity, handle)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
