{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "import pytz\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_yes_no_answer():\n",
    "    '''\n",
    "    \n",
    "    Gets user response as 'y' or 'n' or 'yes' or 'no' or their case variations.\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    while True:\n",
    "        reply = str(input('Combine?: (y/n): ')).lower().strip()\n",
    "        \n",
    "        if reply == 'y' or reply == 'n':\n",
    "            break\n",
    "        else:\n",
    "            print(\"Please select 'yes' or 'no'\")\n",
    "    \n",
    "    return reply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_dummy_scheds(df):\n",
    "    '''\n",
    "    \n",
    "    Dummy schedules are identified when their Effective From Date is the same as Effective To Date.\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    idx = [i for i in range(df.shape[0]) if df['eff_from'][i] == df['eff_to'][i]]\n",
    "    df = df.drop(idx, axis = 0)\n",
    "    df = df.reset_index(drop = True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_noncurrent_scheds(df, tz):\n",
    "    '''\n",
    "    \n",
    "    Schedules that are, as of today, yet to commence or are no longer in operations.\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    today = datetime.now(tz).date()\n",
    "    idx = [i for i in range(df.shape[0]) \n",
    "           if (today <=  datetime.date(df['eff_from'][i])) or (today >= datetime.date(df['eff_to'][i]))]\n",
    "    \n",
    "    df = df.drop(idx, axis = 0)\n",
    "    df = df.reset_index(drop = True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wrangle_frequency(df):\n",
    "    '''\n",
    "    \n",
    "    Standardize <frequency> values for all schedules as a list of numbers that can take values from 1 to 7 for the\n",
    "    weekdays on which a schedule is operational.\n",
    "    \n",
    "    '''\n",
    "\n",
    "# Convert frequency into a string of numbers\n",
    "    for i in range(df.shape[0]):\n",
    "        if isinstance(df.frequency[i], str):\n",
    "            df.frequency[i] = '1234567'\n",
    "        else:\n",
    "            df.frequency[i] = str(int(df.frequency[i]))\n",
    "\n",
    "# Convert string of numbers into list of numbers\n",
    "        df.frequency[i] = list(df.frequency[i]) # Split str\n",
    "        df.frequency[i] = list(map(int, df.frequency[i])) # Convert from str to int\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_pairs(df, human_intel = 'n'):\n",
    "    '''\n",
    "    \n",
    "    In raw data, each schedule has two legs of information: at origin and at destination. These two legs are\n",
    "    present as different records. Identify pairs and combine them into a single record.\n",
    "    \n",
    "    Allow for human intervetion to identify possible pairs when poor/missing data does not allow for automated \n",
    "    identification.\n",
    "    \n",
    "    Embedded helper function combine_pairs_func() appropriately combines records [i] and [j] and marks record [j] \n",
    "    for deletion.\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    def combine_pairs_func(i, j, drop_idx):\n",
    "\n",
    "        drop_idx.append(j)\n",
    "        \n",
    "        if df.to_time[i] == '': \n",
    "            df.to_time[i] = df.to_time[j]\n",
    "        else: \n",
    "            df.from_time[i] = df.from_time[j]\n",
    "            \n",
    "        return drop_idx\n",
    "    \n",
    "    drop_idx = []        \n",
    "    \n",
    "    # Compare a record with only subsequent records and as long as the subsequent record has not already been\n",
    "    # paired with some other record.\n",
    "    for i in range(df.shape[0] - 1):\n",
    "        if i not in drop_idx:\n",
    "            for j in range(i+1, df.shape[0]):\n",
    "                if j not in drop_idx:\n",
    "                    if df.flight[i] != df.flight[j]: break                   \n",
    "                    else:\n",
    "                        # Automated pairing\n",
    "                        if human_intel == 'n':\n",
    "                            if df.frequency[i] == df.frequency[j] and df['from'][i] == df['from'][j] and df.to[i] == df.to[j]:\n",
    "                                drop_idx = combine_pairs_func(i, j, drop_idx)\n",
    "                                \n",
    "                        # Pairing with human intervention by relaxing the identical frequency constraint\n",
    "                        else:\n",
    "                            if df.to[i] == df.to[j] and df['from'][i] == df['from'][j]:\n",
    "                                if df.to_time[i] == '' and df.from_time[j] == '' and df.from_time[i] != '' and df.to_time[j] != '':\n",
    "                                    display(df.iloc[i, :8], df.iloc[j, :8])\n",
    "                                    display('Possibly Pairs?')\n",
    "                                    reply = get_yes_no_answer()\n",
    "                                    \n",
    "                                    if reply == 'y':\n",
    "                                        drop_idx = combine_pairs_func(i, j, drop_idx)\n",
    "                                    \n",
    "                                elif df.to_time[i] != '' and df.from_time[j] != '' and df.from_time[i] == '' and df.to_time[j] == '':\n",
    "                                    display(df.iloc[i, :8], df.iloc[j, :8])\n",
    "                                    display('Possibly Pairs?')\n",
    "                                    reply = get_yes_no_answer()\n",
    "                                    \n",
    "                                    if reply == 'y':\n",
    "                                        drop_idx = combine_pairs_func(i, j, drop_idx)\n",
    "                            \n",
    "    \n",
    "    df = df.drop(drop_idx, axis = 0)\n",
    "    df = df.reset_index(drop = True)\n",
    "    \n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_freq(df, human_intel = 'n'):\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    Combine multiple schedule records where the schedules in the set differ only in their frequencies. This \n",
    "    requires no human intervention.\n",
    "\n",
    "    Combine multiple schedules where the schedules in the set differ not only in their frequencies but vary \n",
    "    slightly in their <from_time> (or <to_time>) values. This requires human intervention\n",
    "    \n",
    "    Embedded helper function combine_frq_func() appropriately combines records [i] and [j] and marks record [j] \n",
    "    for deletion.\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    def combine_freq_func(i, j, drop_idx):\n",
    "        drop_idx.append(j)\n",
    "        df.frequency[i] = df.frequency[i] + df.frequency[j]\n",
    "        df.frequency[i] = list(set(df.frequency[i]))\n",
    "        return drop_idx\n",
    "        \n",
    "    drop_idx = []    \n",
    "    \n",
    "    for i in range(df.shape[0] - 1):\n",
    "        if i not in drop_idx:\n",
    "            for j in range(i+1, df.shape[0]):\n",
    "                if j not in drop_idx:\n",
    "                    if df.flight[i] != df.flight[j]: break\n",
    "                    else:\n",
    "                    \n",
    "                        # Automated Merging\n",
    "                        if human_intel == 'n':\n",
    "                            if df['from'][i] == df['from'][j] and df.to[i] == df.to[j]:\n",
    "                                if df.to_time[i] == df.to_time[j] and df.from_time[i] == df.from_time[j]:\n",
    "                                    drop_idx = combine_freq_func(i, j, drop_idx)\n",
    "\n",
    "                        # Merging with human intervention by requiring only either to_time or from_time be identical  \n",
    "                        else:\n",
    "                            if df['from'][i] == df['from'][j] and df.to[i] == df.to[j]:\n",
    "                                if df.to_time[i] == df.to_time[j] or df.from_time[i] == df.from_time[j]:\n",
    "\n",
    "                                    display(df.iloc[i, :8], '\\n', df.iloc[j, :8])\n",
    "                                    display('Probably the same flight.')\n",
    "\n",
    "                                    reply = get_yes_no_answer()\n",
    "\n",
    "                                    if reply == 'y':\n",
    "                                        drop_idx = combine_freq_func(i, j, drop_idx)\n",
    "      \n",
    "    df = df.drop(drop_idx, axis = 0)\n",
    "    df = df.reset_index(drop = True)\n",
    "    \n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def separate_orphan_scheds(df, orphan_scheds):\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    After all the processing steps, we are still left with some records that do not have either a \n",
    "    corresponding <from> or a <to> schedule. This is usually due to bad data and will require significant \n",
    "    manual effort to enrich the records and make them available for future analysis.\n",
    "    \n",
    "    We separate such records into a file.\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    orphan_idx = [i for i in range(df.shape[0]) if df.to_time[i] == '' or df.from_time[i] == '']\n",
    "    orphan_scheds = pd.concat([orphan_scheds, df.iloc[orphan_idx]], ignore_index = True)        \n",
    "\n",
    "    df = df.drop(orphan_idx, axis = 0)\n",
    "    df = df.reset_index(drop = True)\n",
    "\n",
    "    return df, orphan_scheds, len(orphan_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_base10_time(df):\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    For easier analysis, we convert the <from_time> and <to_time> from the HH:MM format to HH:XX format, \n",
    "    where the hours HH are from 0-24 but the minutes are converted from 0-60 to 0-99 i.e. the minutes are\n",
    "    represented on a decimel scale.\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    for i in range(df.shape[0]):\n",
    "        foo = df.from_time[i].split(':')\n",
    "        df.from_time[i] = round((int(foo[0]) + int(foo[1])/60), 2)\n",
    "        foo = df.to_time[i].split(':')\n",
    "        df.to_time[i] = round((int(foo[0]) + int(foo[1])/60), 2)\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing for Alliance_Air\n",
      "(Step VI) Read Stage-1 processed data\n",
      "          Dropped dummy schedules\n",
      "          Dropped non-current schedules: now has 356 records\n",
      "\n",
      "Standardizing frequency and finding <from> and <to> legs of schedules... (may take time)\n",
      "(Step VII) Standardized <frequency> data\n",
      "           Paired the <from> and <to> legs of schedules: now has 231 records\n",
      "\n",
      "Finding schedules split only by frequency... (may take time)\n",
      "(Step VIII) Merged schedules split only by frequency\n",
      "            Paired resultant <from> and <to> legs of a schedule: now has 189 records\n",
      "\n",
      "Finding schedules split by frequency for human confirmation\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "operator                    AAS\n",
       "flight                   9I 538\n",
       "aircraft                 ATR 72\n",
       "frequency    [1, 2, 3, 4, 5, 7]\n",
       "from                        HYD\n",
       "from_time                 17:25\n",
       "to                          VGA\n",
       "to_time                        \n",
       "Name: 20, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'\\n'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "operator        AAS\n",
       "flight       9I 538\n",
       "aircraft     ATR 72\n",
       "frequency       [6]\n",
       "from            HYD\n",
       "from_time     17:30\n",
       "to              VGA\n",
       "to_time            \n",
       "Name: 21, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Probably the same flight.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combine?: (y/n): y\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "operator        AAS\n",
       "flight       9I 752\n",
       "aircraft     ATR 72\n",
       "frequency       [6]\n",
       "from            IXI\n",
       "from_time     15:20\n",
       "to              CCU\n",
       "to_time            \n",
       "Name: 108, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'\\n'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "operator                    AAS\n",
       "flight                   9I 752\n",
       "aircraft                 ATR 72\n",
       "frequency    [1, 2, 3, 4, 5, 7]\n",
       "from                        IXI\n",
       "from_time                 16:35\n",
       "to                          CCU\n",
       "to_time                        \n",
       "Name: 109, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Probably the same flight.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combine?: (y/n): n\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "operator                 AAS\n",
       "flight                9I 873\n",
       "aircraft              ATR 72\n",
       "frequency    [1, 2, 3, 4, 5]\n",
       "from                     ISK\n",
       "from_time               8:20\n",
       "to                       AMD\n",
       "to_time                     \n",
       "Name: 147, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'\\n'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "operator        AAS\n",
       "flight       9I 873\n",
       "aircraft     ATR 72\n",
       "frequency       [6]\n",
       "from            ISK\n",
       "from_time     11:30\n",
       "to              AMD\n",
       "to_time            \n",
       "Name: 148, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Probably the same flight.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combine?: (y/n): n\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "operator        AAS\n",
       "flight       9I 874\n",
       "aircraft     ATR 72\n",
       "frequency       [6]\n",
       "from            AMD\n",
       "from_time          \n",
       "to              ISK\n",
       "to_time       14:30\n",
       "Name: 149, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'\\n'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "operator                 AAS\n",
       "flight                9I 874\n",
       "aircraft              ATR 72\n",
       "frequency    [1, 2, 3, 4, 5]\n",
       "from                     AMD\n",
       "from_time                   \n",
       "to                       ISK\n",
       "to_time                14:25\n",
       "Name: 152, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Probably the same flight.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combine?: (y/n): y\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "operator                    AAS\n",
       "flight                   9I 893\n",
       "aircraft                 ATR 72\n",
       "frequency    [1, 3, 4, 5, 6, 7]\n",
       "from                        MYQ\n",
       "from_time                  8:30\n",
       "to                          COK\n",
       "to_time                        \n",
       "Name: 177, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'\\n'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "operator        AAS\n",
       "flight       9I 893\n",
       "aircraft     ATR 72\n",
       "frequency       [2]\n",
       "from            MYQ\n",
       "from_time     10:25\n",
       "to              COK\n",
       "to_time            \n",
       "Name: 178, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Probably the same flight.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combine?: (y/n): n\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "operator                    AAS\n",
       "flight                   9I 895\n",
       "aircraft                 ATR 72\n",
       "frequency    [1, 3, 4, 5, 6, 7]\n",
       "from                        MYQ\n",
       "from_time                 15:20\n",
       "to                          GOI\n",
       "to_time                        \n",
       "Name: 181, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'\\n'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "operator        AAS\n",
       "flight       9I 895\n",
       "aircraft     ATR 72\n",
       "frequency       [2]\n",
       "from            MYQ\n",
       "from_time     17:05\n",
       "to              GOI\n",
       "to_time            \n",
       "Name: 182, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Probably the same flight.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combine?: (y/n): n\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "operator        AAS\n",
       "flight       9I 896\n",
       "aircraft     ATR 72\n",
       "frequency       [2]\n",
       "from            GOI\n",
       "from_time          \n",
       "to              MYQ\n",
       "to_time       20:30\n",
       "Name: 183, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'\\n'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "operator                    AAS\n",
       "flight                   9I 896\n",
       "aircraft                 ATR 72\n",
       "frequency    [1, 3, 4, 5, 6, 7]\n",
       "from                        GOI\n",
       "from_time                      \n",
       "to                          MYQ\n",
       "to_time                   18:50\n",
       "Name: 184, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Probably the same flight.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combine?: (y/n): n\n",
      "(Step IX) Merge schedules split by frequency but with human confirmation\n",
      "          Paired resultant <from> and <to> legs of a schedule: now has 185 records\n",
      "\n",
      "Finding possible pairs for human confirmation\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "operator           AAS\n",
       "flight          9I 731\n",
       "aircraft        ATR 72\n",
       "frequency    [4, 6, 7]\n",
       "from               GAU\n",
       "from_time             \n",
       "to                 TEZ\n",
       "to_time           8:40\n",
       "Name: 92, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "operator           AAS\n",
       "flight          9I 731\n",
       "aircraft        ATR 72\n",
       "frequency    [3, 6, 7]\n",
       "from               GAU\n",
       "from_time         8:00\n",
       "to                 TEZ\n",
       "to_time               \n",
       "Name: 94, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Possibly Pairs?'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combine?: (y/n): y\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "operator           AAS\n",
       "flight          9I 732\n",
       "aircraft        ATR 72\n",
       "frequency    [4, 6, 7]\n",
       "from               TEZ\n",
       "from_time         9:00\n",
       "to                 GAU\n",
       "to_time               \n",
       "Name: 96, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "operator           AAS\n",
       "flight          9I 732\n",
       "aircraft        ATR 72\n",
       "frequency    [3, 6, 7]\n",
       "from               TEZ\n",
       "from_time             \n",
       "to                 GAU\n",
       "to_time          10:00\n",
       "Name: 97, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Possibly Pairs?'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combine?: (y/n): y\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "operator              AAS\n",
       "flight             9I 733\n",
       "aircraft           ATR 72\n",
       "frequency    [1, 2, 4, 5]\n",
       "from                  GAU\n",
       "from_time            8:00\n",
       "to                    IXT\n",
       "to_time                  \n",
       "Name: 99, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "operator              AAS\n",
       "flight             9I 733\n",
       "aircraft           ATR 72\n",
       "frequency    [1, 2, 3, 5]\n",
       "from                  GAU\n",
       "from_time                \n",
       "to                    IXT\n",
       "to_time              9:25\n",
       "Name: 101, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Possibly Pairs?'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combine?: (y/n): y\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "operator                    AAS\n",
       "flight                   9I 873\n",
       "aircraft                 ATR 72\n",
       "frequency    [1, 2, 3, 4, 5, 6]\n",
       "from                        ISK\n",
       "from_time                      \n",
       "to                          AMD\n",
       "to_time                    9:35\n",
       "Name: 144, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "operator                 AAS\n",
       "flight                9I 873\n",
       "aircraft              ATR 72\n",
       "frequency    [1, 2, 3, 4, 5]\n",
       "from                     ISK\n",
       "from_time               8:20\n",
       "to                       AMD\n",
       "to_time                     \n",
       "Name: 145, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Possibly Pairs?'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combine?: (y/n): y\n",
      "(Step X) Pair <from> and <to> legs of a schedule but with human confirmantion\n",
      "         : now has 181 records\n",
      "(Step XI) Separated  30 orphan schedules: now has 151 records\n",
      "(Step XII) Translated <from_time> and <to_time> to base-10 format\n",
      "           and added 151 records to final processed schedule file\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "\n",
    "Read the data files processed in the earlier stage, one at a time, and run them through the various \n",
    "processing steps. Details and workings of individual processing steps are captured in the helper functions \n",
    "above.\n",
    "\n",
    "'''\n",
    "\n",
    "# Set up defaults\n",
    "stage_1_data_dir_path = './data/processed/stage-1'\n",
    "stage_2_data_dir_path = './data/processed/stage-2'\n",
    "orphan_data_dir_path = './data/processed/orphan_scheds'\n",
    "tz = pytz.timezone('Asia/Calcutta')\n",
    "\n",
    "# Getting list of files in the stage-1 directory and stage-2 file directories\n",
    "_, _, stage_1_file_names = next(os.walk(stage_1_data_dir_path))\n",
    "_, _, stage_2_file_names = next(os.walk(stage_2_data_dir_path))\n",
    "\n",
    "# Retaining only pkl files from stage-1 directory and stage-2 file directories\n",
    "stage_1_file_names = [value for value in stage_1_file_names if '.pkl' in value]\n",
    "stage_2_file_names = [value for value in stage_2_file_names if '.pkl' in value]\n",
    "\n",
    "file_names = [value for value in stage_1_file_names if value not in stage_2_file_names]\n",
    "\n",
    "# Processing individual files\n",
    "for file_name in file_names:\n",
    "    print('\\nProcessing for %s' % file_name.split('.')[0])\n",
    "    readpath = stage_1_data_dir_path + '/' + file_name\n",
    "    dat = pd.read_pickle(readpath)  \n",
    "    dat = drop_dummy_scheds(dat)\n",
    "    dat = drop_noncurrent_scheds(dat, tz)\n",
    "    print('(Step VI) Read Stage-1 processed data')\n",
    "    print('          Dropped dummy schedules')\n",
    "    print('          Dropped non-current schedules: now has %i records' % dat.shape[0])\n",
    "    \n",
    "    #####################################################\n",
    "    \n",
    "    print('\\nStandardizing frequency and finding <from> and <to> legs of schedules... (may take time)')\n",
    "    dat = wrangle_frequency(dat)\n",
    "    # Sorting the records on flight number. This makes the subsequent steps faster\n",
    "    dat = dat.astype({'flight' : 'str'})\n",
    "    dat = dat.sort_values(by = ['flight'], axis = 0, ignore_index = True) \n",
    "    dat = make_pairs(dat)\n",
    "    print('(Step VII) Standardized <frequency> data')\n",
    "    print('           Paired the <from> and <to> legs of schedules: now has %i records' % dat.shape[0])\n",
    "    \n",
    "    ######################################################\n",
    "        \n",
    "    print('\\nFinding schedules split only by frequency... (may take time)')\n",
    "    dat = merge_freq(dat)    \n",
    "    dat = make_pairs(dat)\n",
    "    print('(Step VIII) Merged schedules split only by frequency')\n",
    "    print('            Paired resultant <from> and <to> legs of a schedule: now has %i records' % dat.shape[0])\n",
    "    \n",
    "    ######################################################\n",
    "    \n",
    "    print('\\nFinding schedules split by frequency for human confirmation\\n')\n",
    "    dat = merge_freq(dat, 'y')\n",
    "    dat = make_pairs(dat)\n",
    "    print('(Step IX) Merge schedules split by frequency but with human confirmation')\n",
    "    print('          Paired resultant <from> and <to> legs of a schedule: now has %i records' % dat.shape[0])\n",
    "    \n",
    "    ######################################################\n",
    "    \n",
    "    print('\\nFinding possible pairs for human confirmation\\n')\n",
    "    dat = make_pairs(dat, 'y')\n",
    "    print('(Step X) Pair <from> and <to> legs of a schedule but with human confirmantion')\n",
    "    print('         : now has %i records' % dat.shape[0])\n",
    "    \n",
    "    ######################################################\n",
    "    \n",
    "    orphan_scheds = pd.DataFrame(data = None, columns = dat.columns)\n",
    "    dat, orphan_scheds, orphans = separate_orphan_scheds(dat, orphan_scheds)\n",
    "    print('(Step XI) Separated % i orphan schedules: now has %i records' % (orphans, dat.shape[0]))\n",
    "    \n",
    "    ######################################################\n",
    "    \n",
    "    dat = to_base10_time(dat)\n",
    "    dat.to_pickle(stage_2_data_dir_path + '/' + file_name)\n",
    "    orphan_scheds.to_pickle(orphan_data_dir_path + '/orphan_' + file_name)\n",
    "    print('(Step XII) Translated <from_time> and <to_time> to base-10 format')\n",
    "    print('           and added %i records to final processed schedule file' % dat.shape[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "Combine the individual files processed earlier into a single file - for schedules and for orphans - and store the \n",
    "final files in three different formats - pickle, excel and csv.\n",
    "\n",
    "'''\n",
    "\n",
    "# Set up defaults\n",
    "stage_2_data_dir_path = './data/processed/stage-2'\n",
    "orphan_data_dir_path = './data/processed/orphan_scheds'\n",
    "final_data_dir_path = './data/processed/final'\n",
    "\n",
    "# Getting list of files in the processed data directory and orphan data directory\n",
    "_, _, stage_2_file_names = next(os.walk(stage_2_data_dir_path))\n",
    "_, _, orphan_file_names = next(os.walk(orphan_data_dir_path))\n",
    "\n",
    "# Retaining only pkl files from processed data directory and orphan data directory\n",
    "stage_2_file_names = [value for value in stage_2_file_names if '.pkl' in value]\n",
    "orphan_file_names = [value for value in orphan_file_names if '.pkl' in value]\n",
    "\n",
    "final_data = pd.DataFrame(data = None, columns = dat.columns)\n",
    "orphan_data = pd.DataFrame(data = None, columns = dat.columns)\n",
    "\n",
    "\n",
    "for file_name in stage_2_file_names:\n",
    "    readpath = stage_2_data_dir_path + '/' + file_name\n",
    "    foo = pd.read_pickle(readpath)\n",
    "    final_data = pd.concat([final_data, foo], ignore_index = True)\n",
    "    \n",
    "for file_name in orphan_file_names:\n",
    "    readpath = orphan_data_dir_path + '/' + file_name\n",
    "    foo = pd.read_pickle(readpath)\n",
    "    orphan_data = pd.concat([orphan_data, foo], ignore_index = True)\n",
    "\n",
    "\n",
    "final_data.to_pickle(final_data_dir_path + '/' + 'all-sched.pkl')\n",
    "orphan_data.to_pickle(final_data_dir_path + '/' + 'all-orphan.pkl')\n",
    "\n",
    "final_data.to_excel(final_data_dir_path + '/' + 'all-sched.xlsx', index = False)\n",
    "orphan_data.to_excel(final_data_dir_path + '/' + 'all-orphan.xlsx', index = False)\n",
    "                     \n",
    "final_data.to_csv(final_data_dir_path + '/' + 'all-sched.csv', index = False)\n",
    "orphan_data.to_csv(final_data_dir_path + '/' + 'all-orphan.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
