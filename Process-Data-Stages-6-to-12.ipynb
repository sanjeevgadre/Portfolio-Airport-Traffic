{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "import pytz\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_yes_no_answer():\n",
    "    '''\n",
    "    \n",
    "    Gets user response as 'y' or 'n' or 'yes' or 'no' or their case variations.\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    while True:\n",
    "        reply = str(input('Combine?: (y/n): ')).lower().strip()\n",
    "        \n",
    "        if reply == 'y' or reply == 'n':\n",
    "            break\n",
    "        else:\n",
    "            print(\"Please select 'yes' or 'no'\")\n",
    "    \n",
    "    return reply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_dummy_scheds(df):\n",
    "    '''\n",
    "    \n",
    "    Dummy schedules are identified when their Effective From Date is the same as Effective To Date.\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    idx = [i for i in range(df.shape[0]) if df['eff_from'][i] == df['eff_to'][i]]\n",
    "    df = df.drop(idx, axis = 0)\n",
    "    df = df.reset_index()\n",
    "    df = df.drop(['index'], axis = 1)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_noncurrent_scheds(df, tz):\n",
    "    '''\n",
    "    \n",
    "    Schedules that are, as of today, yet to commence or are no longer in operations.\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    today = datetime.now(tz).date()\n",
    "    idx = [i for i in range(df.shape[0]) \n",
    "           if (today <=  datetime.date(df['eff_from'][i])) or (today >= datetime.date(df['eff_to'][i]))]\n",
    "    \n",
    "    df = df.drop(idx, axis = 0)\n",
    "    df = df.reset_index()\n",
    "    df = df.drop('index', axis = 1)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wrangle_frequency(df):\n",
    "    '''\n",
    "    \n",
    "    Standardize <frequency> values for all schedules as a list of numbers that can take values from 1 to 7 for the\n",
    "    weekdays on which a schedule is operational.\n",
    "    \n",
    "    '''\n",
    "\n",
    "# Convert frequency into a string of numbers\n",
    "    for i in range(df.shape[0]):\n",
    "        if isinstance(df.frequency[i], str):\n",
    "            df.frequency[i] = '1234567'\n",
    "        else:\n",
    "            df.frequency[i] = str(int(df.frequency[i]))\n",
    "\n",
    "# Convert string of numbers into list of numbers\n",
    "        df.frequency[i] = list(df.frequency[i]) # Split str\n",
    "        df.frequency[i] = list(map(int, df.frequency[i])) # Convert from str to int\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_pairs(df, human_intel = 'n'):\n",
    "    '''\n",
    "    \n",
    "    In raw data, each schedule has two legs of information: at origin and at destination. These two legs are\n",
    "    present as different records. Identify pairs and combine them into a single record.\n",
    "    \n",
    "    Allow for human intervetion to identify possible pairs when poor/missing data does not allow for automated \n",
    "    identification.\n",
    "    \n",
    "    Embedded helper function combine_pairs_func() appropriately combines records [i] and [j] and marks record [j] \n",
    "    for deletion.\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    def combine_pairs_func(i, j, drop_idx):\n",
    "\n",
    "        drop_idx.append(j)\n",
    "        \n",
    "        if df.to_time[i] == '': \n",
    "            df.to_time[i] = df.to_time[j]\n",
    "        else: \n",
    "            df.from_time[i] = df.from_time[j]\n",
    "            \n",
    "        return drop_idx\n",
    "    \n",
    "    drop_idx = []        \n",
    "    \n",
    "    # Compare a record with only subsequent records and as long as the subsequent record has not already been\n",
    "    # paired with some other record.\n",
    "    for i in range(df.shape[0] - 1):\n",
    "        if i not in drop_idx:\n",
    "            for j in range(i+1, df.shape[0]):\n",
    "                if j not in drop_idx:\n",
    "                    if df.flight[i] != df.flight[j]: break                   \n",
    "                    else:\n",
    "                        # Automated pairing\n",
    "                        if human_intel == 'n':\n",
    "                            if df.frequency[i] == df.frequency[j] and df['from'][i] == df['from'][j] and df.to[i] == df.to[j]:\n",
    "                                drop_idx = combine_pairs_func(i, j, drop_idx)\n",
    "                                \n",
    "                        # Pairing with human intervention by relaxing the identical frequency constraint\n",
    "                        else:\n",
    "                            if df.to[i] == df.to[j] and df['from'][i] == df['from'][j]:\n",
    "                                if df.to_time[i] == '' and df.from_time[j] == '' and df.from_time[i] != '' and df.to_time[j] != '':\n",
    "                                    display(df.iloc[i, :8], df.iloc[j, :8])\n",
    "                                    display('Possibly Pairs?')\n",
    "                                    reply = get_yes_no_answer()\n",
    "                                    \n",
    "                                    if reply == 'y':\n",
    "                                        drop_idx = combine_pairs_func(i, j, drop_idx)\n",
    "                                    \n",
    "                                elif df.to_time[i] != '' and df.from_time[j] != '' and df.from_time[i] == '' and df.to_time[j] == '':\n",
    "                                    display(df.iloc[i, :8], df.iloc[j, :8])\n",
    "                                    display('Possibly Pairs?')\n",
    "                                    reply = get_yes_no_answer()\n",
    "                                    \n",
    "                                    if reply == 'y':\n",
    "                                        drop_idx = combine_pairs_func(i, j, drop_idx)\n",
    "                            \n",
    "    \n",
    "    df = df.drop(drop_idx, axis = 0)\n",
    "    df = df.reset_index()\n",
    "    df = df.drop('index', axis = 1)\n",
    "    \n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_freq(df, human_intel = 'n'):\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    Combine multiple schedule records where the schedules in the set differ only in their frequencies. This \n",
    "    requires no human intervention.\n",
    "\n",
    "    Combine multiple schedules where the schedules in the set differ not only in their frequencies but vary \n",
    "    slightly in their <from_time> (or <to_time>) values. This requires human intervention\n",
    "    \n",
    "    Embedded helper function combine_frq_func() appropriately combines records [i] and [j] and marks record [j] \n",
    "    for deletion.\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    def combine_freq_func(i, j, drop_idx):\n",
    "        drop_idx.append(j)\n",
    "        df.frequency[i] = df.frequency[i] + df.frequency[j]\n",
    "        df.frequency[i] = list(set(df.frequency[i]))\n",
    "        return drop_idx\n",
    "        \n",
    "    drop_idx = []    \n",
    "    \n",
    "    for i in range(df.shape[0] - 1):\n",
    "        if i not in drop_idx:\n",
    "            for j in range(i+1, df.shape[0]):\n",
    "                if j not in drop_idx:\n",
    "                    if df.flight[i] != df.flight[j]: break\n",
    "                    else:\n",
    "                    \n",
    "                        # Automated Merging\n",
    "                        if human_intel == 'n':\n",
    "                            if df['from'][i] == df['from'][j] and df.to[i] == df.to[j]:\n",
    "                                if df.to_time[i] == df.to_time[j] and df.from_time[i] == df.from_time[j]:\n",
    "                                    drop_idx = combine_freq_func(i, j, drop_idx)\n",
    "\n",
    "                        # Merging with human intervention by requiring only either to_time or from_time be identical  \n",
    "                        else:\n",
    "                            if df['from'][i] == df['from'][j] and df.to[i] == df.to[j]:\n",
    "                                if df.to_time[i] == df.to_time[j] or df.from_time[i] == df.from_time[j]:\n",
    "\n",
    "                                    display(df.iloc[i, :8], '\\n', df.iloc[j, :8])\n",
    "                                    display('Probably the same flight.')\n",
    "\n",
    "                                    reply = get_yes_no_answer()\n",
    "\n",
    "                                    if reply == 'y':\n",
    "                                        drop_idx = combine_freq_func(i, j, drop_idx)\n",
    "      \n",
    "    df = df.drop(drop_idx, axis = 0)\n",
    "    df = df.reset_index()\n",
    "    df = df.drop('index', axis = 1)\n",
    "    \n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def separate_orphan_scheds(df, orphan_scheds):\n",
    "    \n",
    "    orphan_idx = [i for i in range(df.shape[0]) if df.to_time[i] == '' or df.from_time[i] == '']\n",
    "    orphan_scheds = pd.concat([orphan_scheds, df.iloc[orphan_idx]], ignore_index = True)        \n",
    "\n",
    "    df = df.drop(orphan_idx, axis = 0)\n",
    "    df = df.reset_index()\n",
    "    df = df.drop('index', axis = 1)\n",
    "\n",
    "    return df, orphan_scheds, len(orphan_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_base10_time(df):\n",
    "    \n",
    "    for i in range(df.shape[0]):\n",
    "        foo = df.from_time[i].split(':')\n",
    "        df.from_time[i] = round((int(foo[0]) + int(foo[1])/60), 2)\n",
    "        foo = df.to_time[i].split(':')\n",
    "        df.to_time[i] = round((int(foo[0]) + int(foo[1])/60), 2)\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing for TruJet\n",
      "(Stage VI) Read Stage-1 processed data\n",
      "           Dropped dummy schedules\n",
      "           Dropped non-current schedules: now has 160 records\n",
      "\n",
      "Standardizing frequency and finding <from> and <to> legs of schedules... (will take time)\n",
      "(Stage VII) Standardized <frequency> data\n",
      "            Paired the <from> and <to> legs of schedules: now has 104 records\n",
      "\n",
      "Finding schedules split only by frequency... (will take time)\n",
      "(Stage VIII) Merged schedules split only by frequency\n",
      "             Paired resultant <from> and <to> legs of a schedule: now has 94 records\n",
      "\n",
      "Finding schedules split by frequency for human confirmation\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "operator        TRJ\n",
       "flight       2T 110\n",
       "aircraft     ATR 72\n",
       "frequency       [2]\n",
       "from            BLR\n",
       "from_time     11:35\n",
       "to              HYD\n",
       "to_time            \n",
       "Name: 3, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'\\n'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "operator                    TRJ\n",
       "flight                   2T 110\n",
       "aircraft                 ATR 72\n",
       "frequency    [1, 3, 4, 5, 6, 7]\n",
       "from                        BLR\n",
       "from_time                 12:10\n",
       "to                          HYD\n",
       "to_time                        \n",
       "Name: 5, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Probably the same flight.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/airtraffic/lib/python3.7/site-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    883\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 884\u001b[0;31m                 \u001b[0mident\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdin_socket\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    885\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/airtraffic/lib/python3.7/site-packages/jupyter_client/session.py\u001b[0m in \u001b[0;36mrecv\u001b[0;34m(self, socket, mode, content, copy)\u001b[0m\n\u001b[1;32m    802\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 803\u001b[0;31m             \u001b[0mmsg_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_multipart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    804\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mzmq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZMQError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/airtraffic/lib/python3.7/site-packages/zmq/sugar/socket.py\u001b[0m in \u001b[0;36mrecv_multipart\u001b[0;34m(self, flags, copy, track)\u001b[0m\n\u001b[1;32m    474\u001b[0m         \"\"\"\n\u001b[0;32m--> 475\u001b[0;31m         \u001b[0mparts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrack\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrack\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    476\u001b[0m         \u001b[0;31m# have first part already, only loop while more to receive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket._recv_copy\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/airtraffic/lib/python3.7/site-packages/zmq/backend/cython/checkrc.pxd\u001b[0m in \u001b[0;36mzmq.backend.cython.checkrc._check_rc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-82-de0af8eab455>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\nFinding schedules split by frequency for human confirmation\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m     \u001b[0mdat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmerge_freq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'y'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m     \u001b[0mdat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_pairs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'(Stage IX) Merge schedules split by frequency but with human confirmation'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-79-f0a727dadc98>\u001b[0m in \u001b[0;36mmerge_freq\u001b[0;34m(df, human_intel)\u001b[0m\n\u001b[1;32m     43\u001b[0m                                     \u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Probably the same flight.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m                                     \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_yes_no_answer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m                                     \u001b[0;32mif\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'y'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-201f8dc60e5b>\u001b[0m in \u001b[0;36mget_yes_no_answer\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Combine?: (y/n): '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'y'\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'n'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/airtraffic/lib/python3.7/site-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    857\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 859\u001b[0;31m             \u001b[0mpassword\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    860\u001b[0m         )\n\u001b[1;32m    861\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/airtraffic/lib/python3.7/site-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Set up defaults\n",
    "stage_1_data_dir_path = './data/processed/stage-1'\n",
    "processed_data_dir_path = './data/processed'\n",
    "orphan_data_dir_path = './data/processed/orphan_scheds'\n",
    "tz = pytz.timezone('Asia/Calcutta')\n",
    "\n",
    "# Getting list of files in the stage-1 directory and processed file directory\n",
    "_, _, stage_1_file_names = next(os.walk(stage_1_data_dir_path))\n",
    "_, _, processed_file_names = next(os.walk(processed_data_dir_path))\n",
    "\n",
    "# Retaining only pkl files from stage-1 directory and processed file directory\n",
    "stage_1_file_names = [value for value in stage_1_file_names if '.pkl' in value]\n",
    "processed_file_names = [value for value in processed_file_names if '.pkl' in value]\n",
    "\n",
    "file_names = [value for value in stage_1_file_names if value not in processed_file_names]\n",
    "\n",
    "file_names = ['TruJet.pkl']\n",
    "\n",
    "# Processing individual files\n",
    "for file_name in file_names:\n",
    "    print('\\nProcessing for %s' % file_name.split('.')[0])\n",
    "    \n",
    "    readpath = stage_1_data_dir_path + '/' + file_name\n",
    "    dat = pd.read_pickle(readpath)  \n",
    "    dat = drop_dummy_scheds(dat)\n",
    "    dat = drop_noncurrent_scheds(dat, tz)\n",
    "    print('(Stage VI) Read Stage-1 processed data')\n",
    "    print('           Dropped dummy schedules')\n",
    "    print('           Dropped non-current schedules: now has %i records' % dat.shape[0])\n",
    "    \n",
    "    print('\\nStandardizing frequency and finding <from> and <to> legs of schedules... (will take time)')\n",
    "    dat = wrangle_frequency(dat)\n",
    "    \n",
    "    # Sorting the records on flight number. This makes the subsequent steps faster\n",
    "    dat = dat.astype({'flight' : 'str'})\n",
    "    dat = dat.sort_values(by = ['flight'], axis = 0, ignore_index = True)\n",
    "    \n",
    "    dat = make_pairs(dat)\n",
    "    print('(Stage VII) Standardized <frequency> data')\n",
    "    print('            Paired the <from> and <to> legs of schedules: now has %i records' % dat.shape[0])\n",
    "    \n",
    "    print('\\nFinding schedules split only by frequency... (will take time)')\n",
    "    dat = merge_freq(dat)\n",
    "    dat = make_pairs(dat)\n",
    "    \n",
    "    # Doing it once over again.....may not be required..... \n",
    "    dat = merge_freq(dat)\n",
    "    dat = make_pairs(dat)\n",
    "    print('(Stage VIII) Merged schedules split only by frequency')\n",
    "    print('             Paired resultant <from> and <to> legs of a schedule: now has %i records' % dat.shape[0])\n",
    "    \n",
    "    print('\\nFinding schedules split by frequency for human confirmation\\n')\n",
    "    dat = merge_freq(dat, 'y')\n",
    "    dat = make_pairs(dat)\n",
    "    print('(Stage IX) Merge schedules split by frequency but with human confirmation')\n",
    "    print('           Paired resultant <from> and <to> legs of a schedule: now has %i records' % dat.shape[0])\n",
    "    \n",
    "    print('\\nFinding possible pairs for human confirmation\\n')\n",
    "    dat = make_pairs(dat, 'y')\n",
    "    print('(Stage X) Pair <from> and <to> legs of a schedule but with human confirmantion')\n",
    "    print('          : now has %i records' % dat.shape[0])\n",
    "    \n",
    "    orphan_scheds = pd.DataFrame(data = None, columns = dat.columns)\n",
    "        \n",
    "    dat, orphan_scheds, orphans = separate_orphan_scheds(dat, orphan_scheds)\n",
    "    print('(Stage XI) Separated % i orphan schedules: now has %i records' % (orphans, dat.shape[0]))\n",
    "    \n",
    "    dat = to_base10_time(dat)\n",
    "    dat.to_pickle(processed_data_dir_path + '/' + file_name)\n",
    "    orphan_scheds.to_pickle(orphan_data_dir_path + '/orphan_' + file_name)\n",
    "    \n",
    "    \n",
    "    print('(Stage XII) Translated <from_time> and <to_time> to base-10 format')\n",
    "    print('            and added %i records to final processed schedule file' % dat.shape[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up defaults\n",
    "processed_data_dir_path = './data/processed'\n",
    "orphan_data_dir_path = './data/processed/orphan_scheds'\n",
    "\n",
    "# Getting list of files in the processed data directory and orphan data directory\n",
    "_, _, processed_file_names = next(os.walk(processed_data_dir_path))\n",
    "_, _, orphan_file_names = next(os.walk(orphan_data_dir_path))\n",
    "\n",
    "\n",
    "# Retaining only pkl files from processed data directory and orphan data directory\n",
    "processed_file_names = [value for value in processed_file_names if '.pkl' in value]\n",
    "orphan_file_names = [value for value in orphan_file_names if '.pkl' in value]\n",
    "\n",
    "processed_data = pd.DataFrame(data = None, columns = dat.columns)\n",
    "orphan_data = pd.DataFrame(data = None, columns = dat.columns)\n",
    "\n",
    "for file_name in processed_file_names:\n",
    "    readpath = processed_data_dir_path + '/' + file_name\n",
    "    foo = pd.read_pickle(readpath)\n",
    "    processed_data = pd.concat([processed_data, foo], ignore_index = True)\n",
    "    \n",
    "for file_name in orphan_file_names:\n",
    "    readpath = orphan_data_dir_path + '/' + file_name\n",
    "    foo = pd.read_pickle(readpath)\n",
    "    orphan_data = pd.concat([orphan_data, foo], ignore_index = True)\n",
    "\n",
    "\n",
    "processed_data.to_pickle(processed_data_dir_path + '/' + 'all-sched.pkl')\n",
    "orphan_data.to_pickle(orphan_data_dir_path + '/' + 'all-orphan.pkl')\n",
    "\n",
    "processed_data.to_excel(processed_data_dir_path + '/' + 'all-sched.xlsx')\n",
    "orphan_data.to_excel(orphan_data_dir_path + '/' + 'all-orphan.xlsx')\n",
    "                     \n",
    "processed_data.to_csv(processed_data_dir_path + '/' + 'all-sched.csv')\n",
    "orphan_data.to_csv(orphan_data_dir_path + '/' + 'all-orphan.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
